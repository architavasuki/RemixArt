{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import sys\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from torch.utils.data import DataLoader\n",
    "import re\n",
    "sys.path.append('.')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "/home/himanshu/Workplace/Incubator Project/RemixArt/charCNN\n"
    }
   ],
   "source": [
    "# def load(filename) -> 'Any':\n",
    "#     with open(filename,'rb') as file:\n",
    "#         return pickle.load(file)\n",
    "\n",
    "# args = load('config.p')\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'We are training our model on CUB dataset. CUB contains 200 bird species with 11,788 images. Since 80% of birds in this dataset have object-image size ratios of less than 0.5, as a pre-processing step, we crop all images to ensure that bounding boxes of birds have greater-than-0.75 object-image size ratios.'"
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "source": [
    "text = '''We are training our model on CUB dataset. CUB contains 200 bird species with 11,788 images. Since 80% of birds in this dataset have object-image size ratios of less than 0.5, as a pre-processing step, we crop all images to ensure that bounding boxes of birds have greater-than-0.75 object-image size ratios.'''\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"batch_size\": 1,#args.batch_size,\n",
    "                       \"shuffle\": True,\n",
    "                       \"num_workers\": args.workers,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab = \"abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'\\\"/\\\\|_@#$%^&*~`+ =<>()[]{}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    for text in (os.listdir(path)):\n",
    "        with open(os.path.join(path,text),'r') as file:\n",
    "            texts.append(str(file.read()))\n",
    "            labels.append(text[:-4])\n",
    "    return texts, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "([\"and she's buying the stairway to heaven.\",\n  'help! I need somebody, help, not just anybody, help! I need someone to helppppp!'],\n ['1', '2'])"
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "source": [
    "load_data('training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "\n",
    "    def __init__(self, texts, labels, args):\n",
    "        self.vocab = args.vocab\n",
    "        self.max_len = args.max_length\n",
    "\n",
    "        self.length = len(texts)\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.stopwords = set(list(re.split('',\"!\\\"#$%&'()*+, -./:;<=>?@[\\]^_`{|}~\")) + list(stopwords.words('english')))\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def preprocess(self,text):\n",
    "        text = text.lower()\n",
    "        word_token = nltk.word_tokenize(text)\n",
    "        word_token = [word for word in word_token if word not in self.stopwords]\n",
    "        return word_token\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        raw_text = self.texts[index]\n",
    "        processed_text = self.preprocess(raw_text)\n",
    "        print(np.array(processed_text))\n",
    "        \n",
    "        label = self.labels[index]\n",
    "\n",
    "        return np.array(processed_text), label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = TextDataset(load_data('training')[0], load_data('training')[1],args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[\"'s\" 'buying' 'stairway' 'heaven']['help' 'need' 'somebody' 'help' 'anybody' 'help' 'need' 'someone'\n 'helppppp']\n"
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset,**params)\n",
    "X = iter(dataloader)\n",
    "X = X.next()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_uniform(m,mean=0.0,var=0.05):\n",
    "    classname = m.__class__.__name__\n",
    "    # for every Linear layer in a model..\n",
    "    if classname.find('Linear') != -1:\n",
    "        # apply a uniform distribution to the weights and a bias=0\n",
    "        m.weight.data.uniform_(mean, var)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CharCNN,self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "\n",
    "                        nn.Conv1d(len(args.vocab), 256, kernel_size=7, padding=0),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool1d(3),\n",
    "                        nn.Conv1d(256, 256, kernel_size=7, padding=0),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool1d(3),\n",
    "                        nn.Conv1d(256, 256, kernel_size=3, padding=0),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv1d(256, 256, kernel_size=3, padding=0),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv1d(256, 256, kernel_size=3, padding=0),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv1d(256, 256, kernel_size=3, padding=0),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool1d(3),\n",
    "                        nn.Flatten(),\n",
    "                        nn.Linear(256*34,1024),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(0.5),\n",
    "                        nn.Linear(1024, 1024),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(0.5)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "CharCNN(\n  (model): Sequential(\n    (0): Conv1d(70, 256, kernel_size=(7,), stride=(1,))\n    (1): ReLU()\n    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv1d(256, 256, kernel_size=(7,), stride=(1,))\n    (4): ReLU()\n    (5): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n    (7): ReLU()\n    (8): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n    (9): ReLU()\n    (10): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n    (11): ReLU()\n    (12): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n    (13): ReLU()\n    (14): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n    (15): Flatten()\n    (16): Linear(in_features=8704, out_features=1024, bias=True)\n    (17): ReLU()\n    (18): Dropout(p=0.5, inplace=False)\n    (19): Linear(in_features=1024, out_features=1024, bias=True)\n    (20): ReLU()\n    (21): Dropout(p=0.5, inplace=False)\n  )\n)"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "net = CharCNN()\n",
    "net.apply(weights_init_uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['help', 'need', 'somebody', 'help', 'anybody', 'help', 'need', 'someone', 'helppppp']\n[\"'s\", 'buying', 'stairway', 'heaven']\n"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([2, 1024])"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "net(X[0].view(-1,70,1024)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.]],\n \n         [[0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.]]]),\n tensor([1, 2])]"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitremixartconda754be6cf19a94920834a6bc6331bcd85",
   "display_name": "Python 3.7.7 64-bit ('RemixArt': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}